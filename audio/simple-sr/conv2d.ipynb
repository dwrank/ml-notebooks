{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2aa1f5b9-efc9-4d03-9dac-d11c8b7c5e30",
   "metadata": {},
   "source": [
    "# Implement Conv2D Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c090374-88e6-49e8-b0f2-0d04b6de057e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-28 10:49:04.946593: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import numpy as np\n",
    "import math\n",
    "import h5py\n",
    "from datetime import datetime\n",
    "\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b132515-7d8e-4497-9e42-f4af0b080fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = pathlib.Path('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b955358b-9b63-403e-a343-eb970df08e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_waveform(wavfile):\n",
    "    x = tf.io.read_file(str(wavfile))\n",
    "    x, sample_rate = tf.audio.decode_wav(x, desired_channels=1, desired_samples=16000)\n",
    "    return tf.squeeze(x, axis=-1)\n",
    "\n",
    "\n",
    "def get_spectrogram(waveform):\n",
    "    # Convert the waveform to a spectrogram via a STFT\n",
    "    spectrogram = tf.signal.stft(waveform, frame_length=255, frame_step=128)\n",
    "\n",
    "    # Obtain the magnitude of the STFT\n",
    "    spectrogram = tf.abs(spectrogram)\n",
    "\n",
    "    # Add a 'channels' dimension, so that the spectrogram can be used as an\n",
    "    # image-like input data w/ convolution layers, which expect shape\n",
    "    # (batch_size, height, width, channels)\n",
    "    spectrogram = spectrogram[..., tf.newaxis]\n",
    "    return spectrogram\n",
    "\n",
    "def relu(x):\n",
    "    return x.clip(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf75d89-30ac-43d8-9abe-f90931c7243e",
   "metadata": {},
   "source": [
    "## Get the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "343c7e70-f0fa-43b1-adac-8d3671246e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1, 124, 129, 1]),\n",
       " <tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
       " array([[0.00087561],\n",
       "        [0.00134371],\n",
       "        [0.00557508],\n",
       "        [0.01203688],\n",
       "        [0.01582851],\n",
       "        [0.01979508],\n",
       "        [0.03313684],\n",
       "        [0.05369601],\n",
       "        [0.05009932],\n",
       "        [0.03737277]], dtype=float32)>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "waveform = get_waveform(data_dir/'yes.wav')\n",
    "spec = get_spectrogram(waveform)\n",
    "input_data = spec[tf.newaxis,...]\n",
    "input_data.shape, input_data[0,0,:10,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95facf26-84a9-48ce-848e-0ba513364fc2",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fecf877-9c53-46aa-9488-6ae720bcf962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resizing (Resizing)         (None, 32, 32, 1)         0         \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 32, 32, 1)        3         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 30, 30, 32)        320       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 28, 28, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 12544)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               1605760   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 1032      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,625,611\n",
      "Trainable params: 1,625,608\n",
      "Non-trainable params: 3\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "h5_model = tf.keras.models.load_model('simple-sr.h5')\n",
    "h5_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587cf9d9-8160-4135-85e6-bec0552006ca",
   "metadata": {},
   "source": [
    "## Downsample and Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "007ee942-f808-4efa-b574-6a44d9e2b43c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3, 1), dtype=float32, numpy=\n",
       "array([[[0.00606233],\n",
       "        [0.02537882],\n",
       "        [0.09502278]],\n",
       "\n",
       "       [[0.00929757],\n",
       "        [0.02589507],\n",
       "        [0.49793145]],\n",
       "\n",
       "       [[0.00940787],\n",
       "        [0.02270582],\n",
       "        [0.08615017]]], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downsample the input\n",
    "l1 = h5_model.layers[0]\n",
    "l1_out = l1(input_data)\n",
    "l1_out[0,:3,:3,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "187b5ee3-21e4-4e3f-b46a-8461a65344b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1, 32, 32, 1]),\n",
       " array([[[-0.15616861],\n",
       "         [-0.13089252],\n",
       "         [-0.0397617 ]],\n",
       " \n",
       "        [[-0.15193523],\n",
       "         [-0.13021699],\n",
       "         [ 0.48745418]],\n",
       " \n",
       "        [[-0.1517909 ],\n",
       "         [-0.1343902 ],\n",
       "         [-0.05137172]]], dtype=float32))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize\n",
    "l2 = h5_model.layers[1]\n",
    "l2_out = l2(l1_out.numpy())\n",
    "l2_out_1 = l2_out[0,0:3,0:3,:].numpy()\n",
    "l2_out.shape, l2_out_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7acece-e348-44f2-b3fc-b10faff494ce",
   "metadata": {},
   "source": [
    "## Conv2D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088aa097-1881-4baa-8ca1-dd8b1b36d6b7",
   "metadata": {},
   "source": [
    "### Get the filter and bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c82f4d93-755d-4c62-878c-3ed804b9d73e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[-0.23518433],\n",
       "         [ 0.09234667],\n",
       "         [ 0.02250122]],\n",
       " \n",
       "        [[-0.01212053],\n",
       "         [-0.02103543],\n",
       "         [ 0.06111678]],\n",
       " \n",
       "        [[ 0.2551161 ],\n",
       "         [ 0.13403681],\n",
       "         [-0.07359912]]], dtype=float32),\n",
       " 0.04490134)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l3 = h5_model.layers[2]\n",
    "filter_1 = l3.weights[0].numpy()[:,:,:,0]\n",
    "bias_1 = l3.weights[1].numpy()[0]\n",
    "filter_1, bias_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c555e53-3e0d-4544-8c91-9546de2b5b9f",
   "metadata": {},
   "source": [
    "### Run the tensorflow layer and view results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c88aca10-59ef-4296-b338-149222fe7136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0:00:00.001706\n",
      "(1, 30, 30, 32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
       "array([0.05006328, 0.        , 0.05499763, 0.06115919, 0.        ,\n",
       "       0.20250143, 0.        , 0.12057613, 0.        , 0.        ,\n",
       "       0.13808972, 0.        , 0.16267581, 0.        , 0.04060512,\n",
       "       0.09993156, 0.        , 0.02537329, 0.0487398 , 0.05872676,\n",
       "       0.0784109 , 0.12273581, 0.15963419, 0.01881824, 0.18096109,\n",
       "       0.07243733, 0.        , 0.        , 0.05815995, 0.0821218 ,\n",
       "       0.        , 0.07613287], dtype=float32)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run the tf conv2d layer and print the channel values for the first entry\n",
    "t = datetime.now()\n",
    "l3_out = l3(l2_out.numpy())\n",
    "dt = datetime.now() - t\n",
    "print('Time elapsed: %s' % dt)\n",
    "print(l3_out.numpy().shape)\n",
    "l3_out[0,0,0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6678650-f376-46e5-b1fa-0541028c5880",
   "metadata": {},
   "source": [
    "### Calculate the first entry's value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ee2975d4-f9b4-4515-9775-6befec6063c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.050063286"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the first value\n",
    "np.sum(l2_out_1 * filter_1) + bias_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec64790-5dcc-48fc-b7bf-473fb8225728",
   "metadata": {},
   "source": [
    "### Calculate the channel values for the first entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "74d49fd7-04e2-40b9-bc96-15f5f44d7e36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05006329, 0.        , 0.05499763, 0.06115918, 0.        ,\n",
       "       0.20250145, 0.        , 0.12057613, 0.        , 0.        ,\n",
       "       0.13808972, 0.        , 0.16267581, 0.        , 0.04060512,\n",
       "       0.09993156, 0.        , 0.02537329, 0.0487398 , 0.05872676,\n",
       "       0.07841089, 0.12273582, 0.1596342 , 0.01881824, 0.18096109,\n",
       "       0.07243733, 0.        , 0.        , 0.05815995, 0.0821218 ,\n",
       "       0.        , 0.07613287])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the channel values for the first entry\n",
    "channels = l3.weights[0].numpy().shape[-1]\n",
    "test_output = np.zeros(channels)\n",
    "for i in range(channels):\n",
    "    filter = l3.weights[0].numpy()[:,:,:,i]\n",
    "    bias = l3.weights[1].numpy()[i]\n",
    "    test_output[i] = relu(np.sum(l2_out_1 * filter) + bias)\n",
    "test_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b87f4b-5585-494b-822a-29a814f3922c",
   "metadata": {},
   "source": [
    "### Implement conv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ec268a83-92ba-4972-aea8-f0a33dd6c155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expects a 4 dimensional input (groups, rows, cols, channels)\n",
    "# and filters (rows, cols, in_channels, out_channels)\n",
    "# biases is 1 dimensional matching the number of channels or None\n",
    "def conv2d(input, filters, biases):\n",
    "    output_shape = list(input.shape)\n",
    "    # the edges are not padded, so only points that the filters can cover are included\n",
    "    window_row_size = filters.shape[0]\n",
    "    window_col_size = filters.shape[1]\n",
    "    window_row_margin = window_row_size // 2\n",
    "    window_col_margin = window_col_size // 2\n",
    "    output_shape[1] -= window_row_margin * 2\n",
    "    output_shape[2] -= window_col_margin * 2\n",
    "    # number of channels\n",
    "    channels = filters.shape[-1]\n",
    "    output_shape[-1] = channels\n",
    "    output = np.zeros(output_shape)\n",
    "\n",
    "    groups = input.shape[0]\n",
    "\n",
    "    debug = True\n",
    "    for g in range(groups):\n",
    "        for r in range(output_shape[1]):  # skip unpadded edges\n",
    "            for c in range(output_shape[2]):  # skip unpadded edges\n",
    "\n",
    "                input_window = input[g, r:r+window_row_size, c:c+window_col_size, :]\n",
    "\n",
    "                for ch in range(channels):\n",
    "                    filter = filters[:,:,:,ch]\n",
    "                    try:\n",
    "                        bias = biases[ch]\n",
    "                    except:\n",
    "                        bias = 0.0\n",
    "\n",
    "                    if debug:\n",
    "                        print('in shape: %s, filter: %s' % (input_window.shape, filter.shape))\n",
    "                        debug = False\n",
    "                    val = relu(\n",
    "                        np.sum(input_window * filter) + bias\n",
    "                    )\n",
    "\n",
    "                    output[g,r,c,ch] = val\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5297267c-d172-40c8-960e-f32a6d40e464",
   "metadata": {},
   "source": [
    "### Test the implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2af55df3-7ed6-4924-8dbe-06fc11550e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape: (1, 32, 32, 1)\n",
      "weights shape: (3, 3, 1, 32)\n",
      "\n",
      "in shape: (3, 3, 1), filter: (3, 3, 1)\n",
      "Time elapsed: 0:00:00.594681\n",
      "(1, 30, 30, 32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.05006329, 0.        , 0.05499763, 0.06115918, 0.        ,\n",
       "       0.20250145, 0.        , 0.12057613, 0.        , 0.        ,\n",
       "       0.13808972, 0.        , 0.16267581, 0.        , 0.04060512,\n",
       "       0.09993156, 0.        , 0.02537329, 0.0487398 , 0.05872676,\n",
       "       0.07841089, 0.12273582, 0.1596342 , 0.01881824, 0.18096109,\n",
       "       0.07243733, 0.        , 0.        , 0.05815995, 0.0821218 ,\n",
       "       0.        , 0.07613287])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('input shape: %s' % str(l2_out.numpy().shape))\n",
    "print('weights shape: %s\\n' % str(l3.weights[0].numpy().shape))\n",
    "\n",
    "t = datetime.now()\n",
    "myl3out = conv2d(l2_out.numpy(), l3.weights[0].numpy(), l3.weights[1].numpy())\n",
    "dt = datetime.now() - t\n",
    "print('Time elapsed: %s' % dt)\n",
    "print(myl3out.shape)\n",
    "myl3out[0,0,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "98a71fce-b6ee-45b1-b541-dc7ab07e7950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify values\n",
    "def verify_arrays(a1, a2, tolerance=1e-5):\n",
    "    shapes_equal = a1.shape == a2.shape\n",
    "    print('Shapes match: %s' % str(shapes_equal))\n",
    "    if not shapes_equal:\n",
    "        return\n",
    "\n",
    "    print('Values match: %s' % str(np.all(a1 - a2 < tolerance)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c91ed75c-613f-4893-9853-759f74c95b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes match: True\n",
      "Values match: True\n"
     ]
    }
   ],
   "source": [
    "verify_arrays(l3_out.numpy(), myl3out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cb1b60-e347-4a55-a6d9-335f54a5b173",
   "metadata": {},
   "source": [
    "## The next Conv2D layer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5ede4a-2f97-4695-be0d-2a42e61960fe",
   "metadata": {},
   "source": [
    "### Run the tensorflow layer and view results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bc09f21f-07b1-4fda-8559-fa8408511918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0:00:00.002627\n",
      "(1, 28, 28, 64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(64,), dtype=float32, numpy=\n",
       "array([0.        , 0.13606277, 0.1669277 , 0.        , 0.02371086,\n",
       "       0.        , 0.        , 0.02051658, 0.        , 0.        ,\n",
       "       0.        , 0.01705355, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.01502133, 0.        , 0.2531605 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.185608  , 0.        , 0.        , 0.        , 0.14853501,\n",
       "       0.19258422, 0.19711518, 0.2783924 , 0.        , 0.        ,\n",
       "       0.        , 0.06133013, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.1239159 , 0.00247141, 0.31450033, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.1799986 ], dtype=float32)>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l4 = h5_model.layers[3]\n",
    "t = datetime.now()\n",
    "l4_out = l4(l3_out.numpy())\n",
    "dt = datetime.now() - t\n",
    "print('Time elapsed: %s' % dt)\n",
    "print(l4_out.shape)\n",
    "l4_out[0,0,0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bcabf5-d0f9-4dfa-9f0f-d6435f211d57",
   "metadata": {},
   "source": [
    "### Test the implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "667b3864-ccfe-4dd0-8536-fc426c38a3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape: (1, 30, 30, 32)\n",
      "weights shape: (3, 3, 32, 64)\n",
      "\n",
      "in shape: (3, 3, 32), filter: (3, 3, 32)\n",
      "Time elapsed: 0:00:01.084800\n",
      "(1, 28, 28, 64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.13606275, 0.1669277 , 0.        , 0.02371087,\n",
       "       0.        , 0.        , 0.02051658, 0.        , 0.        ,\n",
       "       0.        , 0.01705355, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.01502134, 0.        , 0.25316052, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.185608  , 0.        , 0.        , 0.        , 0.14853505,\n",
       "       0.19258418, 0.1971152 , 0.27839242, 0.        , 0.        ,\n",
       "       0.        , 0.06133016, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.12391588, 0.0024714 , 0.31450042, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.17999861])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('input shape: %s' % str(l3_out.numpy().shape))\n",
    "print('weights shape: %s\\n' % str(l4.weights[0].numpy().shape))\n",
    "\n",
    "t = datetime.now()\n",
    "myl4out = conv2d(myl3out, l4.weights[0].numpy(), l4.weights[1].numpy())\n",
    "dt = datetime.now() - t\n",
    "print('Time elapsed: %s' % dt)\n",
    "print(myl4out.shape)\n",
    "myl4out[0,0,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3444bbe0-e7c1-4518-808a-a0cf1aa6c315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes match: True\n",
      "Values match: True\n"
     ]
    }
   ],
   "source": [
    "verify_arrays(l4_out.numpy(), myl4out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109047eb-fd3b-4d43-86ee-7dbbfeb3a9ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
