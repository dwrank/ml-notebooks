{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2aa1f5b9-efc9-4d03-9dac-d11c8b7c5e30",
   "metadata": {},
   "source": [
    "# Implement Conv2D Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "4c090374-88e6-49e8-b0f2-0d04b6de057e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import numpy as np\n",
    "import math\n",
    "import h5py\n",
    "from datetime import datetime\n",
    "\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b132515-7d8e-4497-9e42-f4af0b080fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = pathlib.Path('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b955358b-9b63-403e-a343-eb970df08e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_waveform(wavfile):\n",
    "    x = tf.io.read_file(str(wavfile))\n",
    "    x, sample_rate = tf.audio.decode_wav(x, desired_channels=1, desired_samples=16000)\n",
    "    return tf.squeeze(x, axis=-1)\n",
    "\n",
    "\n",
    "def get_spectrogram(waveform):\n",
    "    # Convert the waveform to a spectrogram via a STFT\n",
    "    spectrogram = tf.signal.stft(waveform, frame_length=255, frame_step=128)\n",
    "\n",
    "    # Obtain the magnitude of the STFT\n",
    "    spectrogram = tf.abs(spectrogram)\n",
    "\n",
    "    # Add a 'channels' dimension, so that the spectrogram can be used as an\n",
    "    # image-like input data w/ convolution layers, which expect shape\n",
    "    # (batch_size, height, width, channels)\n",
    "    spectrogram = spectrogram[..., tf.newaxis]\n",
    "    return spectrogram\n",
    "\n",
    "def relu(x):\n",
    "    return x.clip(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf75d89-30ac-43d8-9abe-f90931c7243e",
   "metadata": {},
   "source": [
    "## Get the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "343c7e70-f0fa-43b1-adac-8d3671246e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1, 124, 129, 1]),\n",
       " <tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
       " array([[0.00021577],\n",
       "        [0.00242205],\n",
       "        [0.00827248],\n",
       "        [0.01238501],\n",
       "        [0.01051275],\n",
       "        [0.01144113],\n",
       "        [0.01872324],\n",
       "        [0.02427843],\n",
       "        [0.04116756],\n",
       "        [0.09470174]], dtype=float32)>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "waveform = get_waveform(data_dir/'test/h_yes.wav')\n",
    "spec = get_spectrogram(waveform)\n",
    "input_data = spec[tf.newaxis,...]\n",
    "input_data.shape, input_data[0,0,:10,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95facf26-84a9-48ce-848e-0ba513364fc2",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fecf877-9c53-46aa-9488-6ae720bcf962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resizing (Resizing)         (None, 32, 32, 1)         0         \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 32, 32, 1)        3         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 30, 30, 32)        320       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 28, 28, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 12544)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               1605760   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 1032      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,625,611\n",
      "Trainable params: 1,625,608\n",
      "Non-trainable params: 3\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "h5_model = tf.keras.models.load_model('simple_audio.h5')\n",
    "h5_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587cf9d9-8160-4135-85e6-bec0552006ca",
   "metadata": {},
   "source": [
    "## Downsample and Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "007ee942-f808-4efa-b574-6a44d9e2b43c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3, 1), dtype=float32, numpy=\n",
       "array([[[0.00331012],\n",
       "        [0.0239757 ],\n",
       "        [0.09051986]],\n",
       "\n",
       "       [[0.0023394 ],\n",
       "        [0.01505184],\n",
       "        [0.04525724]],\n",
       "\n",
       "       [[0.00353799],\n",
       "        [0.04326304],\n",
       "        [0.53528124]]], dtype=float32)>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downsample the input\n",
    "l1 = h5_model.layers[0]\n",
    "l1_out = l1(input_data)\n",
    "l1_out[0,:3,:3,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "187b5ee3-21e4-4e3f-b46a-8461a65344b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.15976997],\n",
       "        [-0.13272853],\n",
       "        [-0.04565387]],\n",
       "\n",
       "       [[-0.16104017],\n",
       "        [-0.14440563],\n",
       "        [-0.10488112]],\n",
       "\n",
       "       [[-0.15947178],\n",
       "        [-0.10749058],\n",
       "        [ 0.5363273 ]]], dtype=float32)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize\n",
    "l2 = h5_model.layers[1]\n",
    "l2_out = l2(l1_out.numpy())\n",
    "l2_out_1 = l2_out[0,0:3,0:3,:].numpy()\n",
    "l2_out_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7acece-e348-44f2-b3fc-b10faff494ce",
   "metadata": {},
   "source": [
    "## Conv2D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088aa097-1881-4baa-8ca1-dd8b1b36d6b7",
   "metadata": {},
   "source": [
    "### Get the filter and bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c82f4d93-755d-4c62-878c-3ed804b9d73e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[ 0.23206365],\n",
       "         [ 0.0625558 ],\n",
       "         [-0.01330692]],\n",
       " \n",
       "        [[ 0.01292816],\n",
       "         [ 0.19025595],\n",
       "         [-0.04498325]],\n",
       " \n",
       "        [[-0.30813888],\n",
       "         [-0.15491289],\n",
       "         [ 0.21284764]]], dtype=float32),\n",
       " 0.05159658)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l3 = h5_model.layers[2]\n",
    "filter_1 = l3.weights[0].numpy()[:,:,:,0]\n",
    "bias_1 = l3.weights[1].numpy()[0]\n",
    "filter_1, bias_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c555e53-3e0d-4544-8c91-9546de2b5b9f",
   "metadata": {},
   "source": [
    "### Run the tensorflow layer and view results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "c88aca10-59ef-4296-b338-149222fe7136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0:00:00.001852\n",
      "(1, 30, 30, 32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
       "array([0.16193339, 0.05731045, 0.        , 0.        , 0.        ,\n",
       "       0.07186232, 0.01496371, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.12110282, 0.07639576, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.08606026, 0.        ,\n",
       "       0.08105926, 0.13700518, 0.        , 0.        , 0.        ,\n",
       "       0.01572211, 0.00423875, 0.        , 0.08994323, 0.        ,\n",
       "       0.07543847, 0.        ], dtype=float32)>"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run the tf conv2d layer and print the channel values for the first entry\n",
    "t = datetime.now()\n",
    "l3_out = l3(l2_out.numpy())\n",
    "dt = datetime.now() - t\n",
    "print('Time elapsed: %s' % dt)\n",
    "print(l3_out.numpy().shape)\n",
    "l3_out[0,0,0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6678650-f376-46e5-b1fa-0541028c5880",
   "metadata": {},
   "source": [
    "### Calculate the first entry's value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ee2975d4-f9b4-4515-9775-6befec6063c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16193339"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the first value\n",
    "np.sum(l2_out_1 * filter_1) + bias_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec64790-5dcc-48fc-b7bf-473fb8225728",
   "metadata": {},
   "source": [
    "### Calculate the channel values for the first entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "74d49fd7-04e2-40b9-bc96-15f5f44d7e36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.16193339, 0.05731045, 0.        , 0.        , 0.        ,\n",
       "       0.07186231, 0.01496371, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.12110282, 0.07639575, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.08606026, 0.        ,\n",
       "       0.08105926, 0.13700518, 0.        , 0.        , 0.        ,\n",
       "       0.01572211, 0.00423876, 0.        , 0.08994324, 0.        ,\n",
       "       0.07543847, 0.        ])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the channel values for the first entry\n",
    "channels = l3.weights[0].numpy().shape[-1]\n",
    "test_output = np.zeros(channels)\n",
    "for i in range(channels):\n",
    "    filter = l3.weights[0].numpy()[:,:,:,i]\n",
    "    bias = l3.weights[1].numpy()[i]\n",
    "    test_output[i] = relu(np.sum(l2_out_1 * filter) + bias)\n",
    "test_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b87f4b-5585-494b-822a-29a814f3922c",
   "metadata": {},
   "source": [
    "### Implement conv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "1e4cc356-3764-47cf-81f0-5aa3297422fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expects a 4 dimensional input (groups, rows, cols, 1)\n",
    "# and filters (rows, cols, 1, channels)\n",
    "# biases is 1 dimensional matching the number of channels or None\n",
    "def conv2d(input, filters, biases):\n",
    "    output_shape = list(input.shape)\n",
    "    # the edges are not padded, so only points that the filters can cover are included\n",
    "    window_row_size = filters.shape[0]\n",
    "    window_col_size = filters.shape[1]\n",
    "    window_row_margin = window_row_size // 2\n",
    "    window_col_margin = window_col_size // 2\n",
    "    output_shape[1] -= window_row_margin * 2\n",
    "    output_shape[2] -= window_col_margin * 2\n",
    "    # number of channels\n",
    "    channels = filters.shape[-1]\n",
    "    output_shape[-1] = channels\n",
    "    output = np.zeros(output_shape)\n",
    "\n",
    "    groups = input.shape[0]\n",
    "    rows = input.shape[1]\n",
    "    cols = input.shape[2]\n",
    "\n",
    "    for g in range(groups):\n",
    "        for r in range(rows - window_row_size + 1):  # skip unpadded edges\n",
    "            for c in range(cols - window_col_size + 1):  # skip unpadded edges\n",
    "\n",
    "                input_window = input[g, r:r+window_row_size, c:c+window_col_size, :]\n",
    "\n",
    "                for ch in range(channels):\n",
    "                    filter = filters[:,:,:,ch]\n",
    "                    try:\n",
    "                        bias = biases[ch]\n",
    "                    except:\n",
    "                        bias = 0.0\n",
    "\n",
    "                    val = relu(\n",
    "                        np.sum(\n",
    "                            input_window \\\n",
    "                            * filter)\n",
    "                        + bias)\n",
    "\n",
    "                    output[g,r,c,ch] = val\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5297267c-d172-40c8-960e-f32a6d40e464",
   "metadata": {},
   "source": [
    "### Test the implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "2af55df3-7ed6-4924-8dbe-06fc11550e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0:00:00.598863\n",
      "(1, 30, 30, 32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.16193339, 0.05731045, 0.        , 0.        , 0.        ,\n",
       "       0.07186231, 0.01496371, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.12110282, 0.07639575, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.08606026, 0.        ,\n",
       "       0.08105926, 0.13700518, 0.        , 0.        , 0.        ,\n",
       "       0.01572211, 0.00423876, 0.        , 0.08994324, 0.        ,\n",
       "       0.07543847, 0.        ])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = datetime.now()\n",
    "myl3out = conv2d(l2_out.numpy(), l3.weights[0].numpy(), l3.weights[1].numpy())\n",
    "dt = datetime.now() - t\n",
    "print('Time elapsed: %s' % dt)\n",
    "print(myl3out.shape)\n",
    "myl3out[0,0,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "98a71fce-b6ee-45b1-b541-dc7ab07e7950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify values\n",
    "def verify_conv2d(out1, out2, tolerance=1e-5):\n",
    "    shapes_equal = out1.shape == out2.shape\n",
    "    print('Shapes match: %s' % str(shapes_equal))\n",
    "    if not shapes_equal:\n",
    "        return\n",
    "\n",
    "    print('Values match: %s' % str(np.all(l3_out - myl3out < tolerance)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "c91ed75c-613f-4893-9853-759f74c95b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes match: True\n",
      "Values match: True\n"
     ]
    }
   ],
   "source": [
    "verify_conv2d(l3_out.numpy(), myl3out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cb1b60-e347-4a55-a6d9-335f54a5b173",
   "metadata": {},
   "source": [
    "## The next Conv2D layer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5ede4a-2f97-4695-be0d-2a42e61960fe",
   "metadata": {},
   "source": [
    "### Run the tensorflow layer and view results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "bc09f21f-07b1-4fda-8559-fa8408511918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0:00:00.007967\n",
      "(1, 28, 28, 64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(64,), dtype=float32, numpy=\n",
       "array([0.        , 0.        , 0.        , 0.        , 0.49769944,\n",
       "       0.        , 0.15165518, 0.        , 0.31784678, 0.42159253,\n",
       "       0.        , 0.3958354 , 0.        , 0.        , 0.09659711,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.10127787,\n",
       "       0.2358518 , 0.        , 0.13675866, 0.15558577, 0.18190861,\n",
       "       0.        , 0.09301445, 0.08088657, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.25600177, 0.        , 0.4070488 , 0.        ,\n",
       "       0.        , 0.        , 0.26512337, 0.        , 0.        ,\n",
       "       0.        , 0.15896116, 0.        , 0.19394155, 0.25666392,\n",
       "       0.        , 0.06679156, 0.        , 0.14209348, 0.27046356,\n",
       "       0.        , 0.        , 0.02366456, 0.13287333, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.00255454], dtype=float32)>"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l4 = h5_model.layers[3]\n",
    "t = datetime.now()\n",
    "l4_out = l4(l3_out.numpy())\n",
    "dt = datetime.now() - t\n",
    "print('Time elapsed: %s' % dt)\n",
    "print(l4_out.shape)\n",
    "l4_out[0,0,0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bcabf5-d0f9-4dfa-9f0f-d6435f211d57",
   "metadata": {},
   "source": [
    "### Test the implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "667b3864-ccfe-4dd0-8536-fc426c38a3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0:00:01.096347\n",
      "(1, 28, 28, 64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.49769943,\n",
       "       0.        , 0.15165517, 0.        , 0.31784674, 0.42159255,\n",
       "       0.        , 0.39583546, 0.        , 0.        , 0.09659713,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.10127787,\n",
       "       0.23585178, 0.        , 0.13675864, 0.15558576, 0.1819086 ,\n",
       "       0.        , 0.09301444, 0.08088656, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.25600182, 0.        , 0.40704878, 0.        ,\n",
       "       0.        , 0.        , 0.26512334, 0.        , 0.        ,\n",
       "       0.        , 0.15896116, 0.        , 0.19394159, 0.25666391,\n",
       "       0.        , 0.06679156, 0.        , 0.14209349, 0.27046354,\n",
       "       0.        , 0.        , 0.02366454, 0.13287334, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.00255456])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = datetime.now()\n",
    "myl4out = conv2d(myl3out, l4.weights[0].numpy(), l4.weights[1].numpy())\n",
    "dt = datetime.now() - t\n",
    "print('Time elapsed: %s' % dt)\n",
    "print(myl4out.shape)\n",
    "myl4out[0,0,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "3444bbe0-e7c1-4518-808a-a0cf1aa6c315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes match: True\n",
      "Values match: True\n"
     ]
    }
   ],
   "source": [
    "verify_conv2d(l4_out.numpy(), myl4out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109047eb-fd3b-4d43-86ee-7dbbfeb3a9ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
